# ðŸ“š Anime RAG Assistant â€” Project Plan (MVP)

A FastAPI + Gradio-powered chatbot that uses a local LLaMA3 8B model and RAG over subtitle & episode summaries from popular anime series.

---

## âœ… MVP Goals

| Goal | Description |
|------|-------------|
| ðŸ” Ask Qs about anime | Answer episode-level questions via RAG over SRT/summary |
| ðŸ“„ Chunk subtitles + metadata | Use LlamaIndex for ingest + retrieval |
| ðŸ’¬ Stream responses | Serve via vLLM (LLaMA3 8B, OpenAI-compatible) |
| ðŸ§ª Eval output quality | Use [DeepEval](https://github.com/confident-ai/deepeval) (an open-source LLM evaluation framework) + some manual tests |
| ðŸ§  Trace everything | [Langfuse](https://github.com/langfuse/langfuse) (an open-source LLM observability and evaluation platform) integration for traces, latency, prompt versions |
| ðŸ–¥ï¸ Interfaces | Swagger docs + Gradio UI for chat/testing |

---

## ðŸ§± Project Phases

### ðŸ”¹ Phase 1 â€” Data Ingestion & Indexing
- Subtitle/Summary preprocessor: custom parser for `.srt`, `.md`, `.txt`
- Chunking & metadata with `LlamaIndex` (episode ID, speaker, timestamp)
- Use Chroma (local) for persistence

### ðŸ”¹ Phase 2 â€” RAG QA Chain
- Use `LlamaIndex` retriever (dense or hybrid)
- Serve LLaMA3 8B via `vLLM`
- Langfuse tags for model + prompt versioning

### ðŸ”¹ Phase 3 â€” API & UI Integration
- FastAPI backend with `/chat`, `/search`, `/healthz`, `/meta`
- Swagger auto-generated docs
- Gradio UI for testing chat + feedback

### ðŸ”¹ Phase 4 â€” Evaluation
- Add `DeepEval` test cases with `LLMTestCase`
- Manual grading via JSON/YAML test set
- (Optional) `Ragas` for document-grounded eval

### ðŸ”¹ Phase 5 â€” Observability
- Langfuse for full trace logging (input/output/context)
- Tags: episode, model, latency, chunk count
- User feedback (ðŸ‘/ðŸ‘Ž) via Langfuse or local DB

---

## ðŸ§± Directory Structure

```bash
anime_assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.py          # FastAPI entrypoint
â”‚   â”œâ”€â”€ ingest.py          # Subtitle/summary parser â†’ index
â”‚   â”œâ”€â”€ retriever.py       # LlamaIndex retriever setup
â”‚   â”œâ”€â”€ rag_chain.py       # LangChain RAG chain
â”‚   â”œâ”€â”€ models.py          # Pydantic schemas
â”‚   â”œâ”€â”€ langfuse_hook.py   # Langfuse instrumentation
â”‚   â”œâ”€â”€ gradio_ui.py       # Optional UI
â”‚   â””â”€â”€ settings.py        # Central settings
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ metadata/          # episode info
â”‚   â””â”€â”€ index/             # LlamaIndex persist dir
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_eval_deepeval.py
â”‚   â””â”€â”€ qa_cases.json      # manual eval set
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ setup.cfg
â””â”€â”€ README.md
```

---

```mermaid
graph TD
    A[Anime Search Query] --> C[Fetch from Jikan API - Episodes + Summaries]
    C --> D[Chunk Summaries + Store in Vector DB]
    E[User Question] --> F[Retrieval + Prompt Assembly]
    D --> F
    F --> G[vLLM - LLaMA 3 8B]
    G --> H[Answer w/ Episode Context]
    F --> I[Langfuse Trace]
    H --> J[DeepEval Test]
```
